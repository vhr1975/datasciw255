# UC Berkeley Data Science W255: Machine Learning Systems Engineering

This repository contains my coursework and projects for UC Berkeleyâ€™s Data Science W255 (MIDS program). The course focuses on building production-grade machine learning systems, covering the full ML lifecycle from development to deployment and monitoring.

## Course Summary & Learning Objectives

- Develop proficiency in Python programming for data science and ML systems.
- Apply object-oriented programming (OOP) and modular design principles.
- Build, containerize, and deploy ML APIs using modern frameworks.
- Work with data structures, functions, and modules.
- Use Jupyter Notebooks for interactive analysis and reporting.
- Practice data cleaning, transformation, and visualization.
- Gain experience with version control (Git/GitHub) and collaborative workflows.
- Deploy and monitor ML services using Docker, Kubernetes, and cloud tools.

## Labs Overview

### Lab 1: FastAPI ML Application & Containerization
- **Description:** Built a FastAPI web application with multiple endpoints, managed dependencies using Poetry, and containerized the app with Docker. Automated build/run/test with scripts and wrote unit tests using Pytest.
- **Key Skills:** FastAPI, Poetry, Docker, Pytest, API design, automation scripts.

### Lab 2: ML API with Validation & CI/CD
- **Description:** Developed a FastAPI API to predict California housing values, using Pydantic for input validation. Built and ran the app with Docker, tested with Pytest, and explored GitHub Actions for CI/CD.
- **Key Skills:** FastAPI, Pydantic, Docker, Pytest, GitHub Actions, API validation, CI/CD basics.

### Lab 3: (See lab3/README.md for details)
- **Description:** Continued development and deployment practices. (Refer to the lab3 README for specific endpoints, features, and instructions.)
- **Key Skills:** FastAPI, Docker, deployment automation.

### Lab 4: (See lab4/README.md for details)
- **Description:** Further extended the ML API, focusing on modularization, code quality, and deployment. (Refer to the lab4 README for specifics.)
- **Key Skills:** Modular Python, Docker, deployment, code quality.

### Lab 5: Metrics, Load Testing & Monitoring
- **Description:** Deployed the application to Azure Kubernetes Service (AKS), performed load testing with K6, and monitored metrics using Prometheus and Grafana. Analyzed performance and system health.
- **Key Skills:** Kubernetes (AKS), K6 load testing, Prometheus, Grafana, cloud deployment, monitoring.

## Major Projects & Assignments

### Final Project: End-to-End Machine Learning API
- **Description:** Designed, containerized, and deployed a scalable ML API using FastAPI, Redis, Docker, and Kubernetes. Integrated CI/CD, monitoring, and load testing.
- **Key Skills:** API design, containerization, orchestration, cloud deployment, monitoring, and performance testing.

## Technologies Used

- Python 3.x
- Jupyter Notebooks
- FastAPI, Redis, Docker, Kubernetes
- pandas, numpy, matplotlib
- Git & GitHub

## How to Run

1. Clone the repository.
2. Set up a Python virtual environment and install dependencies (`requirements.txt` or `poetry install`).
3. Open and run Jupyter Notebooks for each assignment.
4. For the final project, follow the instructions in `final_project/README.md` to build, deploy, and test the ML API.

## Reflection

This portfolio demonstrates my growth in programming, problem-solving, and building production-ready data science systems. It serves as a foundation for advanced coursework and real-world ML engineering.